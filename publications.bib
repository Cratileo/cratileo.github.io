@InProceedings{Yang2022,
  author    = {Yang, Chenyu and Wang, Yu},
  booktitle = {INTERSPEECH 2022},
  title     = {Robust End-to-end Speaker Diarization with Generic Neural Clustering},
  year      = {2022},
}


@Article{Wang2022,
  author  = {Wang, Yuhao and Duan, Yuxin and Wang, Pingjie and Wang, Yu and Xue, Wei},
  journal = {DCASE2022 Challenge, Technical report},
  title   = {Improving low-resource sound event localization and detection via active learning with domain adaptation},
  year    = {2022},
}

@InProceedings{Zhao2022,
  author    = {Zhao, Zihan and Wang, Yanfeng and Wang, Yu},
  booktitle = {INTERSPEECH 2022},
  title     = {Multi-level Fusion of Wav2vec 2.0 and {BERT} for Multimodal Emotion Recognition},
  year      = {2022},
}

@InProceedings{Chen2023,
  author    = {Chen, Mengxi and Xing, Linyu and Wang, Yu and Zhang, Ya},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title     = {Enhanced multimodal representation learning with cross-modal KD},
  year      = {2023},
  pages     = {11766--11775},
}

@InProceedings{Zhao2023,
  author       = {Zhao, Zihan and Wang, Yu and Wang, Yanfeng},
  booktitle    = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title        = {Knowledge-aware bayesian co-attention for multimodal emotion recognition},
  year         = {2023},
  organization = {IEEE},
  pages        = {1--5},
}

@Article{Jiang2023,
  author  = {Jiang, Shuyang and Wang, Yuhao and Wang, Yu},
  journal = {arXiv preprint arXiv:2306.02907},
  title   = {Selfevolve: A code evolution framework via large language models},
  year    = {2023},
}

@Article{Chen2023a,
  author    = {Chen, Zhe and Liu, Hongcheng and Wang, Yu},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title     = {DialogMCF: Multimodal Context Flow for Audio Visual Scene-Aware Dialog},
  year      = {2023},
  publisher = {IEEE},
}

@InProceedings{Zhu2023,
  author    = {Zhu, Zhiyuan and Liao, Yusheng and Wang, Yu and Guan, Yunfeng},
  booktitle = {INTERSPEECH 2023},
  title     = {Contrastive Learning Based ASR Robust Knowledge Selection For Spoken Dialogue System},
  year      = {2023},
}

@Article{Zhao2024,
  author  = {Zhao, Zihan and Jiang, Yiyang and Liu, Heyang and Wang, Yanfeng and Wang, Yu},
  journal = {IEEE Transactions on Artificial Intelligence},
  title   = {LibriSQA: Pioneering Free-form and Open-ended Spoken Question Answering with a Novel Dataset and Framework},
  year    = {2024},
}

@Article{Liao2023,
  author  = {Liao, Yusheng and Meng, Yutong and Liu, Hongcheng and Wang, Yanfeng and Wang, Yu},
  journal = {arXiv preprint arXiv:2309.02077},
  title   = {An Automatic Evaluation Framework for Multi-turn Medical Consultations Capabilities of Large Language Models},
  year    = {2023},
}

@InProceedings{Zhu2023a,
  author    = {Zhu, Zhiyuan and Liao, Yusheng and Chen, Zhe and Wang, Yu and Guan, Yunfeng},
  booktitle = {Proceedings of The Eleventh Dialog System Technology Challenge},
  title     = {Towards Optimizing Pre-trained Language Model Ensemble Learning for Task-oriented Dialogue System},
  year      = {2023},
  pages     = {144--149},
}

@InProceedings{Liu2024,
  author       = {Liu, Hongcheng and Chen, Zhe and Li, Hui and Wang, Pingjie and Wang, Yanfeng and Wang, Yu},
  booktitle    = {ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title        = {MSG-BART: Multi-Granularity Scene Graph-Enhanced Encoder-Decoder Language Model for Video-Grounded Dialogue Generation},
  year         = {2024},
  organization = {IEEE},
  pages        = {10516--10520},
}

@Article{Yang2023,
  author  = {Yang, Yuchen and Li, Houqiang and Wang, Yanfeng and Wang, Yu},
  journal = {arXiv preprint arXiv:2310.04782},
  title   = {Improving the Reliability of Large Language Models by Leveraging Uncertainty-Aware In-Context Learning},
  year    = {2023},
}

@Article{chen2023redundancy,
  author  = {Chen, Mengxi and Yao, Jiangchao and Xing, Linyu and Wang, Yu and Zhang, Ya and Wang, Yanfeng},
  journal = {arXiv preprint arXiv:2310.14496},
  title   = {Redundancy-Adaptive Multimodal Learning for Imperfect Data},
  year    = {2023},
}

@InProceedings{Yang2023a,
  author    = {Yang, Chenyu and Chen, Mengxi and Wang, Yanfeng and Wang, Yu},
  booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
  title     = {Uncertainty-Guided End-to-End Audio-Visual Speaker Diarization for Far-Field Recordings},
  year      = {2023},
  pages     = {4031--4041},
}

@InProceedings{Liao2023a,
  author    = {Liao, Yusheng and Jiang, Shuyang and Li, Yiqi and Wang, Yu and Wang, Yanfeng},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  title     = {Self-Improvement of Non-autoregressive Model via Sequence-Level Distillation},
  year      = {2023},
  pages     = {14202--14212},
}

@InProceedings{Duan2023,
  author       = {Duan, Yuxin and Yang, Chenyu and Zhao, Zihan and Jiang, Yiyang and Wang, Yanfeng and Wang, Yu},
  booktitle    = {National Conference on Man-Machine Speech Communication},
  title        = {A Comparative Study of Pre-trained Audio and Speech Models for Heart Sound Detection},
  year         = {2023},
  organization = {Springer},
  pages        = {287--301},
}

@InProceedings{Jiang2023a,
  author    = {Jiang, Yiyang and Zhao, Zihan and Duan, Yuxin and Wang, Yan-Feng and Sun, Xin and Wang, Yu},
  booktitle = {2023 National Conference on Man-Machine Speech Communication},
  title     = {Fine-Grained Heart Sound Classification for Congenital Heart Defects Using Multiple Deep Learning Techniques},
  year      = {2023},
}

@InProceedings{Wang2024,
  author    = {Wang, Yuhao and Liao, Yusheng and Liu, Heyang and Liu, Hongcheng and Wang, Yu and Wang, Yanfeng},
  booktitle = {ACL 2024},
  title     = {MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception},
  year      = {2024},
}

@Article{Liu2024a,
  author  = {Liu, Hongcheng and Wang, Pingjie and Wang, Yu and Wang, Yanfeng},
  journal = {arXiv preprint arXiv:2402.11875},
  title   = {M2K-VDG: Model-Adaptive Multimodal Knowledge Anchor Enhanced Video-grounded Dialogue Generation},
  year    = {2024},
}

@InProceedings{Liu2024b,
  author    = {Liu, Hongcheng and Wang, Pingjie and Zhu, Zhiyuan and Wang, Yu and Wang, Yanfeng},
  booktitle = {COLING 2024},
  title     = {CE-VDG: Counterfactual Entropy-based Bias Reduction for Video-grounded Dialogue Generation},
  year      = {2024},
}

@InProceedings{Wang2024a,
  author    = {Wang, Pingjie and Liu, Hongcheng and Wang, Yu and Wang, Yanfeng},
  booktitle = {COLING 2024},
  title     = {Pruning before Fine-tuning: A Retraining-free Compression Framework for Pre-trained Language Models},
  year      = {2024},
}

@InProceedings{Liu2024c,
  author  = {Liu, Heyang and Wang, Yu and Wang, Yanfeng},
  booktitle = {LREC-COLING 2024},
  title   = {Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview},
  year    = {2024},
}

@Article{Liao2024a,
  author  = {Liao, Yusheng and Meng, Yutong and Wang, Yuhao and Liu, Hongcheng and Wang, Yanfeng and Wang, Yu},
  journal = {arXiv preprint arXiv:2403.08495},
  title   = {Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator},
  year    = {2024},
}

@InProceedings{Chen2024,
  author    = {Chen, Zhe and Liu, Heyang and Yu, Wenyi and Sun, Guangzhi and Liu, Hongcheng and Wu, Ji and Zhang, Chao and Wang, Yu and Wang, Yanfeng},
  booktitle = {ACL 2024},
  title     = {M $^{3}$ AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual Academic Lecture Dataset},
  year      = {2024},
}

@Article{Liao2024,
  author    = {Liao, Yusheng and Wang, Yanfeng and Wang, Yu},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title     = {Leveraging Diverse Modeling Contexts with Collaborating Learning for Neural Machine Translation},
  year      = {2024},
  publisher = {IEEE},
}

@Article{Liao2024b,
  author  = {Liao, Yusheng and Jiang, Shuyang and Wang, Yu and Wang, Yanfeng},
  journal = {arXiv preprint arXiv:2404.09027},
  title   = {MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts},
  year    = {2024},
}

@InProceedings{Jiang2024,
  author  = {Jiang, Shuyang and Liao, Yusheng and Zhang, Ya and Wang, Yu and Wang, Yanfeng},
  booktitle = {NeurIPS 2024},
  title   = {TAIA: Large Language Models are Out-of-Distribution Data Learners},
  year    = {2024},
}

@Article{Liao2024c,
  author  = {Liao, Yusheng and Jiang, Shuyang and Chen, Zhe and Wang, Yanfeng and Wang, Yu},
  booktitle = {Findings of EMNLP 2024},
  title   = {MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation},
  year    = {2024},
}

@InProceedings{Guo2024,
  author    = {Guo, YiQiu and Yang, Yuchen and Zhang, Ya and Wang, Yu and Wang, Yanfeng},
  booktitle = {Findings of ACL 2024},
  title     = {DictLLM: Harnessing Key-Value Data Structures with Large Language Models for Enhanced Medical Diagnostics},
  year      = {2024},
}

@InProceedings{Yang2024c,
  author    = {Yang, Yue and Lin, Yuqi and Liu, Hong and Shao, Wenqi and Chen, Runjian and Shang, Hailong and Wang, Yu and Qiao, Yu and Zhang, Kaipeng and Luo, Ping},
  booktitle = {ICML 2024},
  title     = {Position: Towards Implicit Prompt For Text-To-Image Models},
  year      = {2024},
}

@Article{Wang2024b,
  author  = {Wang, Pingjie and Fan, Ziqing and Hu, Shengchao and Chen, Zhe and Wang, Yanfeng and Wang, Yu},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  title   = {Reconstruct the Pruned Model without Any Retraining},
  year    = {2025},
}

@Article{Wang2024c,
  author  = {Wang, Yu and Liu, Heyang and Wang, Yuhao and Xuan, Chuan and Hou, Yixuan and Feng, Sheng and Liu, Hongcheng and Liao, Yusheng and Wang, Yanfeng},
  journal = {arXiv preprint arXiv:2407.20622},
  title   = {Decoding Linguistic Representations of Human Brain},
  year    = {2024},
}

@InProceedings{Yang2024,
  author    = {Yang, Yuchen and Wang, Yu and Wang, Yanfeng},
  booktitle = {Findings of ACL 2024},
  title     = {SDA: Semantic Discrepancy Alignment for Text-conditioned Image Retrieval},
  year      = {2024},
  pages     = {5250--5261},
}

@InProceedings{Yang2024a,
  author    = {Yang, Yuchen and Wang, Yu and Wang, Yanfeng},
  booktitle = {Findings of ACL 2024},
  title     = {CF-TCIR: A Compositor-Free Framework for Hierarchical Text-Conditioned Image Retrieval},
  year      = {2024},
  pages     = {16315--16325},
}

@InProceedings{Feng2024,
  author    = {Feng, Sheng and Liu, Heyang and Wang, Yu and Wang, Yanfeng},
  booktitle = {INTERSPEECH 2024},
  title     = {Towards an End-to-End Framework for Invasive Brain Signal Decoding with Large Language Models},
  year      = {2024},
}

@InProceedings{jiang2025,
  title={Fine-tuning with Reserved Majority for Noise Reduction},
  author={Shuyang Jiang and Yusheng Liao and Yanfeng Wang and Ya Zhang and Yu Wang},
  booktitle={ICLR 2025},
  year={2025},
}

@InProceedings{yang2025,
  title={Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping},
  author={Yang, Yue and Zhang, Shuibai and Shao, Wenqi and Zhang, Kaipeng and Bin, Yi and Wang, Yu and Luo, Ping},
  booktitle={ICLR 2025},
  year={2025},
}

@InProceedings{Zhao2024a,
  title={HSDreport: Heart Sound Diagnosis with Echocardiography Reports},
  author={Zhao, Zihan and Wang, Pingjie and Zhao, Liudan and Yang, Yuchen and Zhang, Ya and Sun, Kun and Sun, Xin and Zhou, Xin and Wang, Yu and Wang, Yanfeng},
  booktitle={Findings of EMNLP 2024},
  year={2024},
}

@InProceedings{Zhu2024,
  title={RA2FD: Distilling Faithfulness into Efficient Dialogue Systems},
  author={Zhu, Zhiyuan and Liao, Yusheng and Xu, Chenxin and Guan, Yunfeng and Wang, Yanfeng and Wang, Yu},
  booktitle={EMNLP 2024},
  year={2024},
}

@InProceedings{Zhu2025,
  title={EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge},
  author={Zhu, Zhiyuan and Liao, Yusheng and Chen, Zhe and Wang, Yuhao and Guan, Yunfeng and Wang, Yanfeng and Wang, Yu},
  booktitle={ACL 2025},
  year={2025},
}

@InProceedings{Chen2025,
  title={Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications},
  author={Chen, Zhe and Liao, Yusheng and Jiang, Shuyang and Wang, Pingjie and Guo YiQiu and Wang, Yanfeng and Wang, Yu},
  booktitle={ACL 2025},
  year={2025},
}

@InProceedings{Liao2025,
  title={ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents},
  author={Liao, Yusheng and Jiang, Shuyang and Wang, Yanfeng and Wang, Yu},
  booktitle={ACL 2025},
  year={2025},
}


@Comment{jabref-meta: databaseType:bibtex;}
